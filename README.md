# Bias-Detector
This project involved collecting data to train and evaluate a model that can detect bias in Planned Parenthood's SexEd chatbot called Roo.

Project Description
Trained and evaluated a model aimed at gaining insights on any bias present in ChatGPT’s responses to questions on sexual health.

Business Goals
Our team was presented with a problem centered around inconsistencies with accurracy in the Planned Parenthood's chatbot Roo. Laws, norms and opinions change on a daily basis which is what accounts for some of the biased and inaccurate responses. Our goal was to determine what types of biases ChatGPT prompts give based on a given keyword and categorize the types of responses ChatGPT gives on sexual health based on a given keyword (biased/ unbiased responses). This would enhance Planned Parenthood and ChatGPT's user experience by offering accurate and up-to date information. The insights from the project can be used to improve Roo, Planned Parenthood’s in-house chatbot, by ensuring that it is accurate in the information it displays to users and that Planned Parenthood has a good brand reputation meaning that they can be trusted leading to higher client retention rates

